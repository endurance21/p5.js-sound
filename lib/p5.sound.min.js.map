{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./audiocontext.js","webpack:///./audioWorklet/processorNames.js","webpack:///../node_modules/startaudiocontext/StartAudioContext.js","webpack:///../node_modules/webpack/buildin/global.js","webpack:///./master.js","webpack:///./helpers.js","webpack:///./amplitude.js"],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","global","TONE_SILENCE_VERSION_LOGGING","audiocontext","window","AudioContext","p5","getAudioContext","userStartAudio","elements","callback","elt","Element","Array","map","e","StartAudioContext","recorderProcessor","soundFileProcessor","amplitudeProcessor","define","factory","TapListener","element","context","this","_dragged","_element","_bindedMove","_moved","_bindedEnd","_ended","addEventListener","isStarted","state","buffer","createBuffer","sampleRate","source","createBufferSource","connect","destination","start","resume","dispose","removeEventListener","promise","Promise","success","checkLoop","requestAnimationFrame","tapListeners","bindTapListener","isArray","NodeList","length","document","querySelectorAll","jquery","toArray","tap","push","body","then","g","Function","p5sound","input","createGain","output","limiter","createDynamicsCompressor","threshold","ratio","knee","disconnect","meter","fftMeter","soundArray","parts","extensions","getMasterVolume","gain","masterVolume","vol","rampTime","tFromNow","now","currentTime","currentVol","cancelScheduledValues","linearRampToValueAtTime","soundOut","_silentNode","freqToMidi","f","mathlog2","Math","log","round","midiToFreq","pow","soundFormats","arguments","toLowerCase","indexOf","disposeSound","registerMethod","_checkFileFormats","paths","path","extTest","split","pop","isFileSupported","pathSplit","pathCore","extension","_mathChain","math","thisChain","nextChain","type","mathOps","Amplitude","smoothing","bufferSize","idealBufferSize","tempAudioWorkletNode","AudioWorkletNode","processorNames","ScriptProcessorNode","safeBufferSize","_workletNode","outputChannelCount","parameterData","processorOptions","normalize","numInputChannels","port","onmessage","event","data","volume","volNorm","stereoVol","stereoVolNorm","setInput","parameters","Signal","unit","panner","getLevel","channel","toggleNormalize","bool","postMessage","smooth","index","splice"],"mappings":"aACE,IAAIA,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUC,QAGnC,IAAIC,EAASJ,EAAiBE,GAAY,CACzCG,EAAGH,EACHI,GAAG,EACHH,QAAS,IAUV,OANAI,EAAQL,GAAUM,KAAKJ,EAAOD,QAASC,EAAQA,EAAOD,QAASF,GAG/DG,EAAOE,GAAI,EAGJF,EAAOD,QAKfF,EAAoBQ,EAAIF,EAGxBN,EAAoBS,EAAIV,EAGxBC,EAAoBU,EAAI,SAASR,EAASS,EAAMC,GAC3CZ,EAAoBa,EAAEX,EAASS,IAClCG,OAAOC,eAAeb,EAASS,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEZ,EAAoBkB,EAAI,SAAShB,GACX,oBAAXiB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAeb,EAASiB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAeb,EAAS,aAAc,CAAEmB,OAAO,KAQvDrB,EAAoBsB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQrB,EAAoBqB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFA1B,EAAoBkB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOrB,EAAoBU,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRzB,EAAoB6B,EAAI,SAAS1B,GAChC,IAAIS,EAAST,GAAUA,EAAOqB,WAC7B,WAAwB,OAAOrB,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAH,EAAoBU,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRZ,EAAoBa,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG/B,EAAoBkC,EAAI,GAIjBlC,EAAoBA,EAAoBmC,EAAI,G,gCClFrD,gCAEAC,EAAOC,8BAA+B,EAMtC,IAAMC,EAAe,IAAIC,OAAOC,aA0ChCC,GAAGT,UAAUU,gBAAkB,WAC7B,OAAOJ,GAwDTG,GAAGT,UAAUW,eAAiB,SAAUC,EAAUC,GAChD,IAAIC,EAAMF,EAQV,OAPIA,aAAoBH,GAAGM,QACzBD,EAAMF,EAASE,IACNF,aAAoBI,OAASJ,EAAS,aAAcH,GAAGM,UAChED,EAAMF,EAASK,IAAI,SAAUC,GAC3B,OAAOA,EAAEJ,OAGNK,IAAkBb,EAAcQ,EAAKD,IAG/BP,Q,+BCvHfnC,EAAOD,QAAU,CACfkD,kBAAmB,qBACnBC,mBAAoB,uBACpBC,mBAAoB,wB,0BCKpBC,EAAO,QAAIC,0BAAA,EAML,WASP,IAAIC,EAAc,SAASC,EAASC,GAEnCC,KAAKC,YAELD,KAAKE,SAAWJ,EAEhBE,KAAKG,YAAcH,KAAKI,OAAOpC,KAAKgC,MACpCA,KAAKK,WAAaL,KAAKM,OAAOtC,KAAKgC,KAAMD,GAEzCD,EAAQS,iBAAiB,aAAcP,KAAKK,YAC5CP,EAAQS,iBAAiB,YAAaP,KAAKG,aAC3CL,EAAQS,iBAAiB,WAAYP,KAAKK,YAC1CP,EAAQS,iBAAiB,UAAWP,KAAKK,aA4D1C,SAASG,EAAUT,GACjB,MAAyB,YAAlBA,EAAQU,MA4FjB,OAnJAZ,EAAYzB,UAAUgC,OAAS,SAASd,GACvCU,KAAKC,aAMNJ,EAAYzB,UAAUkC,OAAS,SAASP,GAClCC,KAAKC,UA0BX,SAAsBF,GAErB,IAAIW,EAASX,EAAQY,aAAa,EAAG,EAAGZ,EAAQa,YAC5CC,EAASd,EAAQe,qBACrBD,EAAOH,OAASA,EAChBG,EAAOE,QAAQhB,EAAQiB,aACvBH,EAAOI,MAAM,GAGTlB,EAAQmB,QACXnB,EAAQmB,SAVV,CAzBenB,GAEdC,KAAKC,aAMNJ,EAAYzB,UAAU+C,QAAU,WAC/BnB,KAAKE,SAASkB,oBAAoB,aAAcpB,KAAKK,YACrDL,KAAKE,SAASkB,oBAAoB,YAAapB,KAAKG,aACpDH,KAAKE,SAASkB,oBAAoB,WAAYpB,KAAKK,YACnDL,KAAKE,SAASkB,oBAAoB,UAAWpB,KAAKK,YAClDL,KAAKG,YAAc,KACnBH,KAAKK,WAAa,KAClBL,KAAKE,SAAW,MA4FjB,SAA2BH,EAASf,EAAUC,GAG7C,IAAIoC,EAAU,IAAIC,QAAQ,SAASC,IAvDpC,SAAmBxB,EAASd,GAavBuB,EAAUT,GACbd,IAZD,SAASuC,IACJhB,EAAUT,GACbd,KAEAwC,sBAAsBD,GAClBzB,EAAQmB,QACXnB,EAAQmB,UANX,GAFD,CAwDYnB,EAASwB,KAIhBG,EAAe,GAoBnB,OAvDD,SAASC,EAAgB7B,EAAS4B,EAAc3B,GAC/C,GAAIX,MAAMwC,QAAQ9B,IAAa+B,UAAY/B,aAAmB+B,SAC7D,IAAK,IAAIrF,EAAI,EAAGA,EAAIsD,EAAQgC,OAAQtF,IACnCmF,EAAgB7B,EAAQtD,GAAIkF,EAAc3B,QAErC,GAAuB,iBAAZD,EACjB6B,EAAgBI,SAASC,iBAAiBlC,GAAU4B,EAAc3B,QAC5D,GAAID,EAAQmC,QAAqC,mBAApBnC,EAAQoC,QAC3CP,EAAgB7B,EAAQoC,UAAWR,EAAc3B,QAC3C,GAAIZ,SAAWW,aAAmBX,QAAQ,CAEhD,IAAIgD,EAAM,IAAItC,EAAYC,EAASC,GACnC2B,EAAaU,KAAKD,IAZpB,CAuCEnD,EADIA,GACO+C,SAASM,KAEKX,EAAc3B,GAGxCsB,EAAQiB,KAAK,WACZ,IAAK,IAAI9F,EAAI,EAAGA,EAAIkF,EAAaI,OAAQtF,IACxCkF,EAAalF,GAAG2E,UAEjBO,EAAe,KAEXzC,GACHA,MAIKoC,KAjLIzB,gC,cCRb,IAAI2C,EAGJA,EAAI,WACH,OAAOvC,KADJ,GAIJ,IAECuC,EAAIA,GAAK,IAAIC,SAAS,cAAb,GACR,MAAOlD,GAEc,iBAAXX,SAAqB4D,EAAI5D,QAOrCpC,EAAOD,QAAUiG,G,+CCsBXE,EAAU,IAvCH,WACXzC,KAAK0C,MAAQhE,IAAaiE,aAC1B3C,KAAK4C,OAASlE,IAAaiE,aAG3B3C,KAAK6C,QAAUnE,IAAaoE,2BAC5B9C,KAAK6C,QAAQE,UAAUtF,OAAS,EAChCuC,KAAK6C,QAAQG,MAAMvF,MAAQ,GAC3BuC,KAAK6C,QAAQI,KAAKxF,MAAQ,EAE1BuC,KAAKtB,aAAeA,IAEpBsB,KAAK4C,OAAOM,aAGZlD,KAAK0C,MAAM3B,QAAQf,KAAK6C,SAGxB7C,KAAK6C,QAAQ9B,QAAQf,KAAK4C,QAG1B5C,KAAKmD,MAAQzE,IAAaiE,aAC1B3C,KAAKoD,SAAW1E,IAAaiE,aAC7B3C,KAAK4C,OAAO7B,QAAQf,KAAKmD,OACzBnD,KAAK4C,OAAO7B,QAAQf,KAAKoD,UAGzBpD,KAAK4C,OAAO7B,QAAQf,KAAKtB,aAAasC,aAGtChB,KAAKqD,WAAa,GAElBrD,KAAKsD,MAAQ,GAGbtD,KAAKuD,WAAa,IAcpB1E,GAAGT,UAAUoF,gBAAkB,WAC7B,OAAOf,EAAQG,OAAOa,KAAKhG,OA6B7BoB,GAAGT,UAAUsF,aAAe,SAAUC,GAAiC,IAA5BC,EAA4B,uDAAjB,EAAGC,EAAc,uDAAH,EAClE,GAAmB,iBAARF,EAAkB,CAC3B,IAAIG,EAAMrB,EAAQ/D,aAAaqF,YAC3BC,EAAavB,EAAQG,OAAOa,KAAKhG,MACrCgF,EAAQG,OAAOa,KAAKQ,sBAAsBH,EAAMD,GAChDpB,EAAQG,OAAOa,KAAKS,wBAAwBF,EAAYF,EAAMD,GAC9DpB,EAAQG,OAAOa,KAAKS,wBAAwBP,EAAKG,EAAMD,EAAWD,OAC7D,KAAID,EAIT,OAAOlB,EAAQG,OAAOa,KAHtBE,EAAI5C,QAAQ0B,EAAQG,OAAOa,QAe/B5E,GAAGT,UAAU+F,SAAWtF,GAAGsF,SAAW1B,EAKtC5D,GAAGsF,SAASC,YAAc3B,EAAQ/D,aAAaiE,aAC/C9D,GAAGsF,SAASC,YAAYX,KAAKhG,MAAQ,EACrCoB,GAAGsF,SAASC,YAAYrD,QAAQ0B,EAAQ/D,aAAasC,aAEtCyB,Q,qPChGf5D,GAAGT,UAAUwC,WAAa,WACxB,OAAO6B,EAAQ/D,aAAakC,YAY9B/B,GAAGT,UAAUiG,WAAa,SAAUC,GAClC,IAAIC,EAAWC,KAAKC,IAAIH,EAAI,KAAOE,KAAKC,IAAI,GAE5C,OADQD,KAAKE,MAAM,GAAKH,GAAY,IAgDb1F,GAAGT,UAAUuG,WAAa,SAAU/H,GAC3D,OAAO,IAAM4H,KAAKI,IAAI,GAAIhI,EAAI,IAAM,KAuDtCiC,GAAGT,UAAUyG,aAAe,WAE1BpC,EAAQc,WAAa,GAErB,IAAK,IAAI/G,EAAI,EAAGA,EAAIsI,UAAUhD,OAAQtF,IAAK,CAEzC,GADAsI,UAAUtI,GAAKsI,UAAUtI,GAAGuI,iBACqC,EAA7D,CAAC,MAAO,MAAO,MAAO,MAAO,OAAOC,QAAQF,UAAUtI,KAGxD,MAAMsI,UAAUtI,GAAK,gCAFrBiG,EAAQc,WAAWnB,KAAK0C,UAAUtI,MAOxCqC,GAAGT,UAAU6G,aAAe,WAC1B,IAAK,IAAIzI,EAAI,EAAGA,EAAIiG,EAAQY,WAAWvB,OAAQtF,IAC7CiG,EAAQY,WAAW7G,GAAG2E,WAM1BtC,GAAGT,UAAU8G,eAAe,SAAUrG,GAAGT,UAAU6G,cAEnDpG,GAAGT,UAAU+G,kBAAoB,SAAUC,GACzC,IAAIC,EAEJ,GAAqB,iBAAVD,EAAoB,CAG7B,IAAIE,GAFJD,EAAOD,GAEYG,MAAM,KAAKC,MAE9B,IAA4D,EAAxD,CAAC,MAAO,MAAO,MAAO,MAAO,OAAOR,QAAQM,IAC9C,IAAKzG,GAAGT,UAAUqH,gBAAgBH,GAGhC,IAFA,IAAII,EAAYL,EAAKE,MAAM,KACvBI,EAAWD,EAAUA,EAAU5D,OAAS,GACnCtF,EAAI,EAAGA,EAAIiG,EAAQc,WAAWzB,OAAQtF,IAAK,CAClD,IAAMoJ,EAAYnD,EAAQc,WAAW/G,GAErC,GADkBqC,GAAGT,UAAUqH,gBAAgBG,GAChC,CACbD,EAAW,GACc,IAArBD,EAAU5D,SACZ6D,GAAYD,EAAU,IAExB,IAAK,IAAIlJ,EAAI,EAAGA,GAAKkJ,EAAU5D,OAAS,EAAGtF,IAAK,CAE9CmJ,GAAY,IADJD,EAAUlJ,GAGpB6I,EAAOM,GAAY,IACnBN,EAAOA,GAAQO,EACf,aAON,IAAK,IAAIpJ,EAAI,EAAGA,EAAIiG,EAAQc,WAAWzB,OAAQtF,IAAK,CAClD,IAAMoJ,EAAYnD,EAAQc,WAAW/G,GAErC,GADkBqC,GAAGT,UAAUqH,gBAAgBG,GAChC,CACbP,EAAOA,EAAO,IAAMO,EACpB,aAOH,GAAqB,WAAjB,EAAOR,GACd,IAAK,IAAI5I,EAAI,EAAGA,EAAI4I,EAAMtD,OAAQtF,IAAK,CACrC,IAAIoJ,EAAYR,EAAM5I,GAAG+I,MAAM,KAAKC,MAEpC,GADgB3G,GAAGT,UAAUqH,gBAAgBG,GAC9B,CAGbP,EAAOD,EAAM5I,GACb,OAIN,OAAO6I,GAMTxG,GAAGT,UAAUyH,WAAa,SAAU5I,EAAG6I,EAAMC,EAAWC,EAAWC,GAEjE,IAAK,IAAIzJ,KAAKS,EAAEiJ,QACVjJ,EAAEiJ,QAAQ1J,aAAcyJ,IAC1BhJ,EAAEiJ,QAAQ1J,GAAG2E,WACb4E,EAAYvJ,GACIS,EAAEiJ,QAAQpE,OAAS,IACjCkE,EAAY/I,EAAEiJ,QAAQ1J,EAAI,KAQhC,OAJAS,EAAEiJ,QAAQH,EAAY,GAAG7C,aACzBjG,EAAEiJ,QAAQH,EAAY,GAAGhF,QAAQ+E,GACjCA,EAAK/E,QAAQiF,GACb/I,EAAEiJ,QAAQH,GAAaD,EAChB7I,GC/LT4B,GAAGsH,UAAY,SAAUC,GAEvBpG,KAAKqG,WD4QA,SAAwBC,GAC7B,IAAID,EAAaC,EAMbC,EAAuB,IAAIC,iBAC7B/D,EAAQ/D,aACR+H,IAAehH,oBAQjB,OANI8G,aAAgCG,sBAClCL,EAAaE,EAAqBF,YAEpCE,EAAqBrD,aACrBqD,EAAuB,KAEhBF,EC7RWM,CAAe,MAGjC3G,KAAKtB,aAAe+D,EAAQ/D,aAC5BsB,KAAK4G,aAAe,IAAIJ,iBACtBxG,KAAKtB,aACL+H,IAAe/G,mBACf,CACEmH,mBAAoB,CAAC,GAErBC,cAAe,CAAEV,UAAWA,GAAa,GACzCW,iBAAkB,CAChBC,WAAW,EACXZ,UAAWA,GAAa,EACxBa,iBAAkB,EAClBZ,WAAYrG,KAAKqG,cAKvBrG,KAAK4G,aAAaM,KAAKC,UAAY,SAAUC,GACnB,cAApBA,EAAMC,KAAKtK,OACbiD,KAAKsH,OAASF,EAAMC,KAAKC,OACzBtH,KAAKuH,QAAUH,EAAMC,KAAKE,QAC1BvH,KAAKwH,UAAYJ,EAAMC,KAAKG,UAC5BxH,KAAKyH,cAAgBL,EAAMC,KAAKI,gBAElCzJ,KAAKgC,MAGPA,KAAK0C,MAAQ1C,KAAK4G,aAElB5G,KAAK4C,OAAS5C,KAAKtB,aAAaiE,aAGhC3C,KAAKsH,OAAS,EACdtH,KAAKuH,QAAU,EACfvH,KAAKwH,UAAY,CAAC,EAAG,GACrBxH,KAAKyH,cAAgB,CAAC,EAAG,GAEzBzH,KAAKgH,WAAY,EAEjBhH,KAAK4G,aAAa7F,QAAQf,KAAK4C,QAC/B5C,KAAK4C,OAAOa,KAAKhG,MAAQ,EAGzBuC,KAAK4C,OAAO7B,QAAQf,KAAKtB,aAAasC,aAGtCyB,EAAQU,MAAMpC,QAAQf,KAAK4G,cAG3BnE,EAAQY,WAAWjB,KAAKpC,OAgD1BnB,GAAGsH,UAAU/H,UAAUsJ,SAAW,SAAU7G,EAAQuF,GAClD3D,EAAQU,MAAMD,aAEVkD,IACFpG,KAAK4G,aAAae,WAAWtK,IAAI,aAAaI,MAAQ2I,GAI1C,MAAVvF,EAIF4B,EAAQU,MAAMpC,QAAQf,KAAK4G,cAIpB/F,aAAkBhC,GAAG+I,OAC5B/G,EAAO+B,OAAO7B,QAAQf,KAAK4G,cAGpB/F,GACPA,EAAOE,QAAQf,KAAK4G,cACpB5G,KAAK4G,aAAa1D,aAClBlD,KAAK4G,aAAa7F,QAAQf,KAAK4C,SAK/BH,EAAQU,MAAMpC,QAAQf,KAAK4G,eAI/B/H,GAAGsH,UAAU/H,UAAU2C,QAAU,SAAU8G,GACrCA,EACEA,EAAKxJ,eAAe,SACtB2B,KAAK4C,OAAO7B,QAAQ8G,EAAKnF,OAEzB1C,KAAK4C,OAAO7B,QAAQ8G,GAGtB7H,KAAK4C,OAAO7B,QAAQf,KAAK8H,OAAO/G,QAAQ0B,EAAQC,SAIpD7D,GAAGsH,UAAU/H,UAAU8E,WAAa,WAC9BlD,KAAK4C,QACP5C,KAAK4C,OAAOM,cA2ChBrE,GAAGsH,UAAU/H,UAAU2J,SAAW,SAAUC,GAC1C,YAAuB,IAAZA,EACLhI,KAAKgH,UACAhH,KAAKyH,cAAcO,GAEnBhI,KAAKwH,UAAUQ,GAEfhI,KAAKgH,UACPhH,KAAKuH,QAELvH,KAAKsH,QAkBhBzI,GAAGsH,UAAU/H,UAAU6J,gBAAkB,SAAUC,GAE/ClI,KAAKgH,UADa,kBAATkB,EACQA,GAEClI,KAAKgH,UAEzBhH,KAAK4G,aAAaM,KAAKiB,YAAY,CACjCpL,KAAM,kBACNiK,UAAWhH,KAAKgH,aAYpBnI,GAAGsH,UAAU/H,UAAUgK,OAAS,SAAU7J,GAC/B,GAALA,GAAUA,EAAI,GAChByB,KAAK4G,aAAaM,KAAKiB,YAAY,CAAEpL,KAAM,YAAaqJ,UAAW7H,KAMvEM,GAAGsH,UAAU/H,UAAU+C,QAAU,WAE/B,IAAIkH,EAAQ5F,EAAQY,WAAW2B,QAAQhF,MACvCyC,EAAQY,WAAWiF,OAAOD,EAAO,GAE7BrI,KAAK0C,QACP1C,KAAK0C,MAAMQ,oBACJlD,KAAK0C,OAEV1C,KAAK4C,SACP5C,KAAK4C,OAAOM,oBACLlD,KAAK4C,QAGd5C,KAAK4G,aAAa1D,oBACXlD,KAAK4G","file":"p5.sound.min.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 4);\n","'use strict';\n\nglobal.TONE_SILENCE_VERSION_LOGGING = true;\n\nimport StartAudioContext from 'startaudiocontext';\n// import Tone from 'Tone/core/Tone';\n\n// Create the Audio Context\nconst audiocontext = new window.AudioContext();\n\n// Tone and p5.sound share the same audio context\n// Tone.context.dispose();\n// console.log(audiocontext)\n// Tone.setContext(audiocontext);\n\n/**\n * <p>Returns the Audio Context for this sketch. Useful for users\n * who would like to dig deeper into the <a target='_blank' href=\n * 'http://webaudio.github.io/web-audio-api/'>Web Audio API\n * </a>.</p>\n *\n * <p>Some browsers require users to startAudioContext\n * with a user gesture, such as touchStarted in the example below.</p>\n *\n * @for p5\n * @method getAudioContext\n * @return {Object}    AudioContext for this sketch\n * @example\n * <div><code>\n *  function draw() {\n *    background(255);\n *    textAlign(CENTER);\n *\n *    if (getAudioContext().state !== 'running') {\n *      text('click to start audio', width/2, height/2);\n *    } else {\n *      text('audio is enabled', width/2, height/2);\n *    }\n *  }\n *\n *  function touchStarted() {\n *    if (getAudioContext().state !== 'running') {\n *      getAudioContext().resume();\n *    }\n *    var synth = new p5.MonoSynth();\n *    synth.play('A4', 0.5, 0, 0.2);\n *  }\n *\n * </div></code>\n */\np5.prototype.getAudioContext = function () {\n  return audiocontext;\n};\n\n/**\n *  <p>It is not only a good practice to give users control over starting\n *  audio. This policy is enforced by many web browsers, including iOS and\n *  <a href=\"https://goo.gl/7K7WLu\" title=\"Google Chrome's autoplay\n *  policy\">Google Chrome</a>, which create the Web Audio API's\n *  <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\"\n *  title=\"Audio Context @ MDN\">Audio Context</a>\n *  in a suspended state.</p>\n *\n *  <p>In these browser-specific policies, sound will not play until a user\n *  interaction event (i.e. <code>mousePressed()</code>) explicitly resumes\n *  the AudioContext, or starts an audio node. This can be accomplished by\n *  calling <code>start()</code> on a <code>p5.Oscillator</code>,\n *  <code> play()</code> on a <code>p5.SoundFile</code>, or simply\n *  <code>userStartAudio()</code>.</p>\n *\n *  <p><code>userStartAudio()</code> starts the AudioContext on a user\n *  gesture. The default behavior will enable audio on any\n *  mouseUp or touchEnd event. It can also be placed in a specific\n *  interaction function, such as <code>mousePressed()</code> as in the\n *  example below. This method utilizes\n *  <a href=\"https://github.com/tambien/StartAudioContext\">StartAudioContext\n *  </a>, a library by Yotam Mann (MIT Licence, 2016).</p>\n *  @param  {Element|Array}   [element(s)] This argument can be an Element,\n *                                Selector String, NodeList, p5.Element,\n *                                jQuery Element, or an Array of any of those.\n *  @param  {Function} [callback] Callback to invoke when the AudioContext\n *                                has started\n *  @return {Promise}            Returns a Promise that resolves when\n *                                       the AudioContext state is 'running'\n *  @method userStartAudio\n *  @for p5\n *  @example\n *  <div><code>\n *  function setup() {\n *    // mimics the autoplay policy\n *    getAudioContext().suspend();\n *\n *    let mySynth = new p5.MonoSynth();\n *\n *    // This won't play until the context has resumed\n *    mySynth.play('A6');\n *  }\n *  function draw() {\n *    background(220);\n *    textAlign(CENTER, CENTER);\n *    text(getAudioContext().state, width/2, height/2);\n *  }\n *  function mousePressed() {\n *    userStartAudio();\n *  }\n *  </code></div>\n */\np5.prototype.userStartAudio = function (elements, callback) {\n  var elt = elements;\n  if (elements instanceof p5.Element) {\n    elt = elements.elt;\n  } else if (elements instanceof Array && elements[0] instanceof p5.Element) {\n    elt = elements.map(function (e) {\n      return e.elt;\n    });\n  }\n  return StartAudioContext(audiocontext, elt, callback);\n};\n\nexport default audiocontext;\n","module.exports = {\n  recorderProcessor: 'recorder-processor',\n  soundFileProcessor: 'sound-file-processor',\n  amplitudeProcessor: 'amplitude-processor',\n};\n","/**\n *  StartAudioContext.js\n *  @author Yotam Mann\n *  @license http://opensource.org/licenses/MIT MIT License\n *  @copyright 2016 Yotam Mann\n */\n(function (root, factory) {\n\tif (typeof define === \"function\" && define.amd) {\n\t\tdefine([], factory)\n\t } else if (typeof module === \"object\" && module.exports) {\n        module.exports = factory()\n\t} else {\n\t\troot.StartAudioContext = factory()\n  }\n}(this, function () {\n\n\t//TAP LISTENER/////////////////////////////////////////////////////////////\n\n\t/**\n\t * @class  Listens for non-dragging tap ends on the given element\n\t * @param {Element} element\n\t * @internal\n\t */\n\tvar TapListener = function(element, context){\n\n\t\tthis._dragged = false\n\n\t\tthis._element = element\n\n\t\tthis._bindedMove = this._moved.bind(this)\n\t\tthis._bindedEnd = this._ended.bind(this, context)\n\n\t\telement.addEventListener(\"touchstart\", this._bindedEnd)\n\t\telement.addEventListener(\"touchmove\", this._bindedMove)\n\t\telement.addEventListener(\"touchend\", this._bindedEnd)\n\t\telement.addEventListener(\"mouseup\", this._bindedEnd)\n\t}\n\n\t/**\n\t * drag move event\n\t */\n\tTapListener.prototype._moved = function(e){\n\t\tthis._dragged = true\n\t};\n\n\t/**\n\t * tap ended listener\n\t */\n\tTapListener.prototype._ended = function(context){\n\t\tif (!this._dragged){\n\t\t\tstartContext(context)\n\t\t}\n\t\tthis._dragged = false\n\t};\n\n\t/**\n\t * remove all the bound events\n\t */\n\tTapListener.prototype.dispose = function(){\n\t\tthis._element.removeEventListener(\"touchstart\", this._bindedEnd)\n\t\tthis._element.removeEventListener(\"touchmove\", this._bindedMove)\n\t\tthis._element.removeEventListener(\"touchend\", this._bindedEnd)\n\t\tthis._element.removeEventListener(\"mouseup\", this._bindedEnd)\n\t\tthis._bindedMove = null\n\t\tthis._bindedEnd = null\n\t\tthis._element = null\n\t};\n\n\t//END TAP LISTENER/////////////////////////////////////////////////////////\n\n\t/**\n\t * Plays a silent sound and also invoke the \"resume\" method\n\t * @param {AudioContext} context\n\t * @private\n\t */\n\tfunction startContext(context){\n\t\t// this accomplishes the iOS specific requirement\n\t\tvar buffer = context.createBuffer(1, 1, context.sampleRate)\n\t\tvar source = context.createBufferSource()\n\t\tsource.buffer = buffer\n\t\tsource.connect(context.destination)\n\t\tsource.start(0)\n\n\t\t// resume the audio context\n\t\tif (context.resume){\n\t\t\tcontext.resume()\n\t\t}\n\t}\n\n\t/**\n\t * Returns true if the audio context is started\n\t * @param  {AudioContext}  context\n\t * @return {Boolean}\n\t * @private\n\t */\n\tfunction isStarted(context){\n\t\t return context.state === \"running\"\n\t}\n\n\t/**\n\t * Invokes the callback as soon as the AudioContext\n\t * is started\n\t * @param  {AudioContext}   context\n\t * @param  {Function} callback\n\t */\n\tfunction onStarted(context, callback){\n\n\t\tfunction checkLoop(){\n\t\t\tif (isStarted(context)){\n\t\t\t\tcallback()\n\t\t\t} else {\n\t\t\t\trequestAnimationFrame(checkLoop)\n\t\t\t\tif (context.resume){\n\t\t\t\t\tcontext.resume()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (isStarted(context)){\n\t\t\tcallback()\n\t\t} else {\n\t\t\tcheckLoop()\n\t\t}\n\t}\n\n\t/**\n\t * Add a tap listener to the audio context\n\t * @param  {Array|Element|String|jQuery} element\n\t * @param {Array} tapListeners\n\t */\n\tfunction bindTapListener(element, tapListeners, context){\n\t\tif (Array.isArray(element) || (NodeList && element instanceof NodeList)){\n\t\t\tfor (var i = 0; i < element.length; i++){\n\t\t\t\tbindTapListener(element[i], tapListeners, context)\n\t\t\t}\n\t\t} else if (typeof element === \"string\"){\n\t\t\tbindTapListener(document.querySelectorAll(element), tapListeners, context)\n\t\t} else if (element.jquery && typeof element.toArray === \"function\"){\n\t\t\tbindTapListener(element.toArray(), tapListeners, context)\n\t\t} else if (Element && element instanceof Element){\n\t\t\t//if it's an element, create a TapListener\n\t\t\tvar tap = new TapListener(element, context)\n\t\t\ttapListeners.push(tap)\n\t\t} \n\t}\n\n\t/**\n\t * @param {AudioContext} context The AudioContext to start.\n\t * @param {Array|String|Element|jQuery=} elements For iOS, the list of elements\n\t *                                               to bind tap event listeners\n\t *                                               which will start the AudioContext. If\n\t *                                               no elements are given, it will bind\n\t *                                               to the document.body.\n\t * @param {Function=} callback The callback to invoke when the AudioContext is started.\n\t * @return {Promise} The promise is invoked when the AudioContext\n\t *                       is started.\n\t */\n\tfunction StartAudioContext(context, elements, callback){\n\n\t\t//the promise is invoked when the AudioContext is started\n\t\tvar promise = new Promise(function(success) {\n\t\t\tonStarted(context, success)\n\t\t})\n\n\t\t// The TapListeners bound to the elements\n\t\tvar tapListeners = []\n\n\t\t// add all the tap listeners\n\t\tif (!elements){\n\t\t\telements = document.body\n\t\t}\n\t\tbindTapListener(elements, tapListeners, context)\n\n\t\t//dispose all these tap listeners when the context is started\n\t\tpromise.then(function(){\n\t\t\tfor (var i = 0; i < tapListeners.length; i++){\n\t\t\t\ttapListeners[i].dispose()\n\t\t\t}\n\t\t\ttapListeners = null\n\n\t\t\tif (callback){\n\t\t\t\tcallback()\n\t\t\t}\n\t\t})\n\n\t\treturn promise\n\t}\n\n\treturn StartAudioContext\n}))","var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n","import audiocontext from './audiocontext';\n// Master contains the master sound output.\nvar Master = function () {\n  this.input = audiocontext.createGain();\n  this.output = audiocontext.createGain();\n\n  //put a hard limiter on the output\n  this.limiter = audiocontext.createDynamicsCompressor();\n  this.limiter.threshold.value = -3;\n  this.limiter.ratio.value = 20;\n  this.limiter.knee.value = 1;\n\n  this.audiocontext = audiocontext;\n\n  this.output.disconnect();\n\n  // connect input to limiter\n  this.input.connect(this.limiter);\n\n  // connect limiter to output\n  this.limiter.connect(this.output);\n\n  // meter is just for global Amplitude / FFT analysis\n  this.meter = audiocontext.createGain();\n  this.fftMeter = audiocontext.createGain();\n  this.output.connect(this.meter);\n  this.output.connect(this.fftMeter);\n\n  // connect output to destination\n  this.output.connect(this.audiocontext.destination);\n\n  // an array of all sounds in the sketch\n  this.soundArray = [];\n  // an array of all musical parts in the sketch\n  this.parts = [];\n\n  // file extensions to search for\n  this.extensions = [];\n};\n\n// create a single instance of the p5Sound / master output for use within this sketch\nconst p5sound = new Master();\n\n/**\n * Returns a number representing the master amplitude (volume) for sound\n * in this sketch.\n *\n * @method getMasterVolume\n * @return {Number} Master amplitude (volume) for sound in this sketch.\n *                  Should be between 0.0 (silence) and 1.0.\n */\np5.prototype.getMasterVolume = function () {\n  return p5sound.output.gain.value;\n};\n\n/**\n *  <p>Scale the output of all sound in this sketch</p>\n *  Scaled between 0.0 (silence) and 1.0 (full volume).\n *  1.0 is the maximum amplitude of a digital sound, so multiplying\n *  by greater than 1.0 may cause digital distortion. To\n *  fade, provide a <code>rampTime</code> parameter. For more\n *  complex fades, see the Envelope class.\n *\n *  Alternately, you can pass in a signal source such as an\n *  oscillator to modulate the amplitude with an audio signal.\n *\n *  <p><b>How This Works</b>: When you load the p5.sound module, it\n *  creates a single instance of p5sound. All sound objects in this\n *  module output to p5sound before reaching your computer's output.\n *  So if you change the amplitude of p5sound, it impacts all of the\n *  sound in this module.</p>\n *\n *  <p>If no value is provided, returns a Web Audio API Gain Node</p>\n *\n *  @method  masterVolume\n *  @param {Number|Object} volume  Volume (amplitude) between 0.0\n *                                     and 1.0 or modulating signal/oscillator\n *  @param {Number} [rampTime]  Fade for t seconds\n *  @param {Number} [timeFromNow]  Schedule this event to happen at\n *                                 t seconds in the future\n */\np5.prototype.masterVolume = function (vol, rampTime = 0, tFromNow = 0) {\n  if (typeof vol === 'number') {\n    var now = p5sound.audiocontext.currentTime;\n    var currentVol = p5sound.output.gain.value;\n    p5sound.output.gain.cancelScheduledValues(now + tFromNow);\n    p5sound.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);\n    p5sound.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);\n  } else if (vol) {\n    vol.connect(p5sound.output.gain);\n  } else {\n    // return the Gain Node\n    return p5sound.output.gain;\n  }\n};\n\n/**\n *  `p5.soundOut` is the p5.sound master output. It sends output to\n *  the destination of this window's web audio context. It contains\n *  Web Audio API nodes including a dyanmicsCompressor (<code>.limiter</code>),\n *  and Gain Nodes for <code>.input</code> and <code>.output</code>.\n *\n *  @property {Object} soundOut\n */\np5.prototype.soundOut = p5.soundOut = p5sound;\n\n// a silent connection to the DesinationNode\n// which will ensure that anything connected to it\n// will not be garbage collected\np5.soundOut._silentNode = p5sound.audiocontext.createGain();\np5.soundOut._silentNode.gain.value = 0;\np5.soundOut._silentNode.connect(p5sound.audiocontext.destination);\n\nexport default p5sound;\n","'use strict';\nimport p5sound from './master';\nimport processorNames from './audioWorklet/processorNames';\n/**\n * @for p5\n */\n\n/**\n * Returns a number representing the sample rate, in samples per second,\n * of all sound objects in this audio context. It is determined by the\n * sampling rate of your operating system's sound card, and it is not\n * currently possile to change.\n * It is often 44100, or twice the range of human hearing.\n *\n * @method sampleRate\n * @return {Number} samplerate samples per second\n */\np5.prototype.sampleRate = function () {\n  return p5sound.audiocontext.sampleRate;\n};\n\n/**\n *  Returns the closest MIDI note value for\n *  a given frequency.\n *\n *  @method freqToMidi\n *  @param  {Number} frequency A freqeuncy, for example, the \"A\"\n *                             above Middle C is 440Hz\n *  @return {Number}   MIDI note value\n */\np5.prototype.freqToMidi = function (f) {\n  var mathlog2 = Math.log(f / 440) / Math.log(2);\n  var m = Math.round(12 * mathlog2) + 69;\n  return m;\n};\n\n/**\n *  Returns the frequency value of a MIDI note value.\n *  General MIDI treats notes as integers where middle C\n *  is 60, C# is 61, D is 62 etc. Useful for generating\n *  musical frequencies with oscillators.\n *\n *  @method  midiToFreq\n *  @param  {Number} midiNote The number of a MIDI note\n *  @return {Number} Frequency value of the given MIDI note\n *  @example\n *  <div><code>\n *  let midiNotes = [60, 64, 67, 72];\n *  let noteIndex = 0;\n *  let midiVal, freq;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(startSound);\n *    osc = new p5.TriOsc();\n *    env = new p5.Envelope();\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap to play', 10, 20);\n *    if (midiVal) {\n *      text('MIDI: ' + midiVal, 10, 40);\n *      text('Freq: ' + freq, 10, 60);\n *    }\n *  }\n *\n *  function startSound() {\n *    // see also: userStartAudio();\n *    osc.start();\n *\n *    midiVal = midiNotes[noteIndex % midiNotes.length];\n *    freq = midiToFreq(midiVal);\n *    osc.freq(freq);\n *    env.ramp(osc, 0, 1.0, 0);\n *\n *    noteIndex++;\n *  }\n *  </code></div>\n */\nexport var midiToFreq = (p5.prototype.midiToFreq = function (m) {\n  return 440 * Math.pow(2, (m - 69) / 12.0);\n});\n\n// This method converts ANSI notes specified as a string \"C4\", \"Eb3\" to a frequency\nexport var noteToFreq = function (note) {\n  if (typeof note !== 'string') {\n    return note;\n  }\n  var wholeNotes = { A: 21, B: 23, C: 24, D: 26, E: 28, F: 29, G: 31 };\n  var value = wholeNotes[note[0].toUpperCase()];\n  var octave = ~~note.slice(-1);\n  value += 12 * (octave - 1);\n\n  switch (note[1]) {\n    case '#':\n      value += 1;\n      break;\n    case 'b':\n      value -= 1;\n      break;\n    default:\n      break;\n  }\n  return midiToFreq(value);\n};\n\n/**\n *  List the SoundFile formats that you will include. LoadSound\n *  will search your directory for these extensions, and will pick\n *  a format that is compatable with the client's web browser.\n *  <a href=\"http://media.io/\">Here</a> is a free online file\n *  converter.\n *\n *  @method soundFormats\n *  @param {String} [...formats] i.e. 'mp3', 'wav', 'ogg'\n *  @example\n *  <div><code>\n *  function preload() {\n *    // set the global sound formats\n *    soundFormats('mp3', 'ogg');\n *\n *    // load either beatbox.mp3, or .ogg, depending on browser\n *    mySound = loadSound('assets/beatbox.mp3');\n *  }\n *\n *  function setup() {\n *       let cnv = createCanvas(100, 100);\n *       background(220);\n *       text('sound loaded! tap to play', 10, 20, width - 20);\n *       cnv.mousePressed(function() {\n *         mySound.play();\n *       });\n *     }\n *  </code></div>\n */\np5.prototype.soundFormats = function () {\n  // reset extensions array\n  p5sound.extensions = [];\n  // add extensions\n  for (var i = 0; i < arguments.length; i++) {\n    arguments[i] = arguments[i].toLowerCase();\n    if (['mp3', 'wav', 'ogg', 'm4a', 'aac'].indexOf(arguments[i]) > -1) {\n      p5sound.extensions.push(arguments[i]);\n    } else {\n      throw arguments[i] + ' is not a valid sound format!';\n    }\n  }\n};\n\np5.prototype.disposeSound = function () {\n  for (var i = 0; i < p5sound.soundArray.length; i++) {\n    p5sound.soundArray[i].dispose();\n  }\n};\n\n// register removeSound to dispose of p5sound SoundFiles, Convolvers,\n// Oscillators etc when sketch ends\np5.prototype.registerMethod('remove', p5.prototype.disposeSound);\n\np5.prototype._checkFileFormats = function (paths) {\n  var path;\n  // if path is a single string, check to see if extension is provided\n  if (typeof paths === 'string') {\n    path = paths;\n    // see if extension is provided\n    var extTest = path.split('.').pop();\n    // if an extension is provided...\n    if (['mp3', 'wav', 'ogg', 'm4a', 'aac'].indexOf(extTest) > -1) {\n      if (!p5.prototype.isFileSupported(extTest)) {\n        var pathSplit = path.split('.');\n        var pathCore = pathSplit[pathSplit.length - 1];\n        for (let i = 0; i < p5sound.extensions.length; i++) {\n          const extension = p5sound.extensions[i];\n          const supported = p5.prototype.isFileSupported(extension);\n          if (supported) {\n            pathCore = '';\n            if (pathSplit.length === 2) {\n              pathCore += pathSplit[0];\n            }\n            for (let i = 1; i <= pathSplit.length - 2; i++) {\n              var p = pathSplit[i];\n              pathCore += '.' + p;\n            }\n            path = pathCore += '.';\n            path = path += extension;\n            break;\n          }\n        }\n      }\n    }\n    // if no extension is provided...\n    else {\n      for (let i = 0; i < p5sound.extensions.length; i++) {\n        const extension = p5sound.extensions[i];\n        const supported = p5.prototype.isFileSupported(extension);\n        if (supported) {\n          path = path + '.' + extension;\n          break;\n        }\n      }\n    }\n  } // end 'if string'\n\n  // path can either be a single string, or an array\n  else if (typeof paths === 'object') {\n    for (var i = 0; i < paths.length; i++) {\n      var extension = paths[i].split('.').pop();\n      var supported = p5.prototype.isFileSupported(extension);\n      if (supported) {\n        // console.log('.'+extension + ' is ' + supported +\n        //  ' supported by your browser.');\n        path = paths[i];\n        break;\n      }\n    }\n  }\n  return path;\n};\n\n/**\n *  Used by Osc and Envelope to chain signal math\n */\np5.prototype._mathChain = function (o, math, thisChain, nextChain, type) {\n  // if this type of math already exists in the chain, replace it\n  for (var i in o.mathOps) {\n    if (o.mathOps[i] instanceof type) {\n      o.mathOps[i].dispose();\n      thisChain = i;\n      if (thisChain < o.mathOps.length - 1) {\n        nextChain = o.mathOps[i + 1];\n      }\n    }\n  }\n  o.mathOps[thisChain - 1].disconnect();\n  o.mathOps[thisChain - 1].connect(math);\n  math.connect(nextChain);\n  o.mathOps[thisChain] = math;\n  return o;\n};\n\n// helper methods to convert audio file as .wav format,\n// will use as saving .wav file and saving blob object\n// Thank you to Matt Diamond's RecorderJS (MIT License)\n// https://github.com/mattdiamond/Recorderjs\nexport function convertToWav(audioBuffer) {\n  var leftChannel, rightChannel;\n  leftChannel = audioBuffer.getChannelData(0);\n\n  // handle mono files\n  if (audioBuffer.numberOfChannels > 1) {\n    rightChannel = audioBuffer.getChannelData(1);\n  } else {\n    rightChannel = leftChannel;\n  }\n\n  var interleaved = interleave(leftChannel, rightChannel);\n\n  // create the buffer and view to create the .WAV file\n  var buffer = new window.ArrayBuffer(44 + interleaved.length * 2);\n  var view = new window.DataView(buffer);\n\n  // write the WAV container,\n  // check spec at: https://web.archive.org/web/20171215131933/http://tiny.systems/software/soundProgrammer/WavFormatDocs.pdf\n\n  // RIFF chunk descriptor\n  writeUTFBytes(view, 0, 'RIFF');\n  view.setUint32(4, 36 + interleaved.length * 2, true);\n  writeUTFBytes(view, 8, 'WAVE');\n  // FMT sub-chunk\n  writeUTFBytes(view, 12, 'fmt ');\n  view.setUint32(16, 16, true);\n  view.setUint16(20, 1, true);\n  // stereo (2 channels)\n  view.setUint16(22, 2, true);\n  view.setUint32(24, p5sound.audiocontext.sampleRate, true);\n  view.setUint32(28, p5sound.audiocontext.sampleRate * 4, true);\n  view.setUint16(32, 4, true);\n  view.setUint16(34, 16, true);\n  // data sub-chunk\n  writeUTFBytes(view, 36, 'data');\n  view.setUint32(40, interleaved.length * 2, true);\n\n  // write the PCM samples\n  var lng = interleaved.length;\n  var index = 44;\n  var volume = 1;\n  for (var i = 0; i < lng; i++) {\n    view.setInt16(index, interleaved[i] * (0x7fff * volume), true);\n    index += 2;\n  }\n\n  return view;\n}\n\n// helper methods to save waves\nfunction interleave(leftChannel, rightChannel) {\n  var length = leftChannel.length + rightChannel.length;\n  var result = new Float32Array(length);\n\n  var inputIndex = 0;\n\n  for (var index = 0; index < length; ) {\n    result[index++] = leftChannel[inputIndex];\n    result[index++] = rightChannel[inputIndex];\n    inputIndex++;\n  }\n  return result;\n}\n\nfunction writeUTFBytes(view, offset, string) {\n  var lng = string.length;\n  for (var i = 0; i < lng; i++) {\n    view.setUint8(offset + i, string.charCodeAt(i));\n  }\n}\n\nexport function safeBufferSize(idealBufferSize) {\n  let bufferSize = idealBufferSize;\n\n  // if the AudioWorkletNode is actually a ScriptProcessorNode created via polyfill,\n  // make sure that our chosen buffer size isn't smaller than the buffer size automatically\n  // selected by the polyfill\n  // reference: https://github.com/GoogleChromeLabs/audioworklet-polyfill/issues/13#issuecomment-425014930\n  let tempAudioWorkletNode = new AudioWorkletNode(\n    p5sound.audiocontext,\n    processorNames.soundFileProcessor\n  );\n  if (tempAudioWorkletNode instanceof ScriptProcessorNode) {\n    bufferSize = tempAudioWorkletNode.bufferSize;\n  }\n  tempAudioWorkletNode.disconnect();\n  tempAudioWorkletNode = null;\n\n  return bufferSize;\n}\n\n// export default {\n//   // convertToWav: convertToWav,\n//   // midiToFreq: midiToFreq,\n//   // noteToFreq: noteToFreq,\n//   // safeBufferSize: safeBufferSize\n// };\n","'use strict';\nimport p5sound from './master';\nimport { safeBufferSize } from './helpers';\nimport processorNames from './audioWorklet/processorNames';\n\n/**\n *  Amplitude measures volume between 0.0 and 1.0.\n *  Listens to all p5sound by default, or use setInput()\n *  to listen to a specific sound source. Accepts an optional\n *  smoothing value, which defaults to 0.\n *\n *  @class p5.Amplitude\n *  @constructor\n *  @param {Number} [smoothing] between 0.0 and .999 to smooth\n *                             amplitude readings (defaults to 0)\n *  @example\n *  <div><code>\n *  let sound, amplitude;\n *\n *  function preload(){\n *    sound = loadSound('assets/beat.mp3');\n *  }\n *  function setup() {\n *    let cnv = createCanvas(100,100);\n *    cnv.mouseClicked(toggleSound);\n *    amplitude = new p5.Amplitude();\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap to play', 20, 20);\n *\n *    let level = amplitude.getLevel();\n *    let size = map(level, 0, 1, 0, 200);\n *    ellipse(width/2, height/2, size, size);\n *  }\n *\n *  function toggleSound() {\n *    if (sound.isPlaying() ){\n *      sound.stop();\n *    } else {\n *      sound.play();\n *    }\n *  }\n *\n *  </code></div>\n */\np5.Amplitude = function (smoothing) {\n  // Set to 2048 for now. In future iterations, this should be inherited or parsed from p5sound's default\n  this.bufferSize = safeBufferSize(2048);\n\n  // set audio context\n  this.audiocontext = p5sound.audiocontext;\n  this._workletNode = new AudioWorkletNode(\n    this.audiocontext,\n    processorNames.amplitudeProcessor,\n    {\n      outputChannelCount: [1],\n\n      parameterData: { smoothing: smoothing || 0 },\n      processorOptions: {\n        normalize: false,\n        smoothing: smoothing || 0,\n        numInputChannels: 2,\n        bufferSize: this.bufferSize,\n      },\n    }\n  );\n\n  this._workletNode.port.onmessage = function (event) {\n    if (event.data.name === 'amplitude') {\n      this.volume = event.data.volume;\n      this.volNorm = event.data.volNorm;\n      this.stereoVol = event.data.stereoVol;\n      this.stereoVolNorm = event.data.stereoVolNorm;\n    }\n  }.bind(this);\n\n  // for connections\n  this.input = this._workletNode;\n\n  this.output = this.audiocontext.createGain();\n\n  // the variables to return\n  this.volume = 0;\n  this.volNorm = 0;\n  this.stereoVol = [0, 0];\n  this.stereoVolNorm = [0, 0];\n\n  this.normalize = false;\n\n  this._workletNode.connect(this.output);\n  this.output.gain.value = 0;\n\n  // this may only be necessary because of a Chrome bug\n  this.output.connect(this.audiocontext.destination);\n\n  // connect to p5sound master output by default, unless set by input()\n  p5sound.meter.connect(this._workletNode);\n\n  // add this p5.SoundFile to the soundArray\n  p5sound.soundArray.push(this);\n};\n\n/**\n *  Connects to the p5sound instance (master output) by default.\n *  Optionally, you can pass in a specific source (i.e. a soundfile).\n *\n *  @method setInput\n *  @for p5.Amplitude\n *  @param {soundObject|undefined} [snd] set the sound source\n *                                       (optional, defaults to\n *                                       master output)\n *  @param {Number|undefined} [smoothing] a range between 0.0 and 1.0\n *                                        to smooth amplitude readings\n *  @example\n *  <div><code>\n *  function preload(){\n *    sound1 = loadSound('assets/beat.mp3');\n *    sound2 = loadSound('assets/drum.mp3');\n *  }\n *  function setup(){\n *    cnv = createCanvas(100, 100);\n *    cnv.mouseClicked(toggleSound);\n *\n *    amplitude = new p5.Amplitude();\n *    amplitude.setInput(sound2);\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap to play', 20, 20);\n *\n *    let level = amplitude.getLevel();\n *    let size = map(level, 0, 1, 0, 200);\n *    ellipse(width/2, height/2, size, size);\n *  }\n *\n *  function toggleSound(){\n *    if (sound1.isPlaying() && sound2.isPlaying()) {\n *      sound1.stop();\n *      sound2.stop();\n *    } else {\n *      sound1.play();\n *      sound2.play();\n *    }\n *  }\n *  </code></div>\n */\np5.Amplitude.prototype.setInput = function (source, smoothing) {\n  p5sound.meter.disconnect();\n\n  if (smoothing) {\n    this._workletNode.parameters.get('smoothing').value = smoothing;\n  }\n\n  // connect to the master out of p5s instance if no snd is provided\n  if (source == null) {\n    console.log(\n      'Amplitude input source is not ready! Connecting to master output instead'\n    );\n    p5sound.meter.connect(this._workletNode);\n  }\n\n  // if it is a p5.Signal\n  else if (source instanceof p5.Signal) {\n    source.output.connect(this._workletNode);\n  }\n  // connect to the sound if it is available\n  else if (source) {\n    source.connect(this._workletNode);\n    this._workletNode.disconnect();\n    this._workletNode.connect(this.output);\n  }\n\n  // otherwise, connect to the master out of p5s instance (default)\n  else {\n    p5sound.meter.connect(this._workletNode);\n  }\n};\n\np5.Amplitude.prototype.connect = function (unit) {\n  if (unit) {\n    if (unit.hasOwnProperty('input')) {\n      this.output.connect(unit.input);\n    } else {\n      this.output.connect(unit);\n    }\n  } else {\n    this.output.connect(this.panner.connect(p5sound.input));\n  }\n};\n\np5.Amplitude.prototype.disconnect = function () {\n  if (this.output) {\n    this.output.disconnect();\n  }\n};\n\n/**\n *  Returns a single Amplitude reading at the moment it is called.\n *  For continuous readings, run in the draw loop.\n *\n *  @method getLevel\n *  @for p5.Amplitude\n *  @param {Number} [channel] Optionally return only channel 0 (left) or 1 (right)\n *  @return {Number}       Amplitude as a number between 0.0 and 1.0\n *  @example\n *  <div><code>\n *  function preload(){\n *    sound = loadSound('assets/beat.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mouseClicked(toggleSound);\n *    amplitude = new p5.Amplitude();\n *  }\n *\n *  function draw() {\n *    background(220, 150);\n *    textAlign(CENTER);\n *    text('tap to play', width/2, 20);\n *\n *    let level = amplitude.getLevel();\n *    let size = map(level, 0, 1, 0, 200);\n *    ellipse(width/2, height/2, size, size);\n *  }\n *\n *  function toggleSound(){\n *    if (sound.isPlaying()) {\n *      sound.stop();\n *    } else {\n *      sound.play();\n *    }\n *  }\n *  </code></div>\n */\np5.Amplitude.prototype.getLevel = function (channel) {\n  if (typeof channel !== 'undefined') {\n    if (this.normalize) {\n      return this.stereoVolNorm[channel];\n    } else {\n      return this.stereoVol[channel];\n    }\n  } else if (this.normalize) {\n    return this.volNorm;\n  } else {\n    return this.volume;\n  }\n};\n\n/**\n * Determines whether the results of Amplitude.process() will be\n * Normalized. To normalize, Amplitude finds the difference the\n * loudest reading it has processed and the maximum amplitude of\n * 1.0. Amplitude adds this difference to all values to produce\n * results that will reliably map between 0.0 and 1.0. However,\n * if a louder moment occurs, the amount that Normalize adds to\n * all the values will change. Accepts an optional boolean parameter\n * (true or false). Normalizing is off by default.\n *\n * @method toggleNormalize\n * @for p5.Amplitude\n * @param {boolean} [boolean] set normalize to true (1) or false (0)\n */\np5.Amplitude.prototype.toggleNormalize = function (bool) {\n  if (typeof bool === 'boolean') {\n    this.normalize = bool;\n  } else {\n    this.normalize = !this.normalize;\n  }\n  this._workletNode.port.postMessage({\n    name: 'toggleNormalize',\n    normalize: this.normalize,\n  });\n};\n\n/**\n *  Smooth Amplitude analysis by averaging with the last analysis\n *  frame. Off by default.\n *\n *  @method smooth\n *  @for p5.Amplitude\n *  @param {Number} set smoothing from 0.0 <= 1\n */\np5.Amplitude.prototype.smooth = function (s) {\n  if (s >= 0 && s < 1) {\n    this._workletNode.port.postMessage({ name: 'smoothing', smoothing: s });\n  } else {\n    console.log('Error: smoothing must be between 0 and 1');\n  }\n};\n\np5.Amplitude.prototype.dispose = function () {\n  // remove reference from soundArray\n  var index = p5sound.soundArray.indexOf(this);\n  p5sound.soundArray.splice(index, 1);\n\n  if (this.input) {\n    this.input.disconnect();\n    delete this.input;\n  }\n  if (this.output) {\n    this.output.disconnect();\n    delete this.output;\n  }\n\n  this._workletNode.disconnect();\n  delete this._workletNode;\n};\n"],"sourceRoot":""}